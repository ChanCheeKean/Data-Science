{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T10:21:18.439633Z",
     "start_time": "2020-10-04T10:21:13.440555Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Material:\n",
    "\n",
    "Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush, \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\", http://arxiv.org/abs/1502.05698\n",
    "\n",
    "Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus, \"End-To-End Memory Networks\", http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T10:21:18.592058Z",
     "start_time": "2020-10-04T10:21:18.441675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./data/train_qa.txt\", \"rb\") as fp:\n",
    "    train_data =  pickle.load(fp)\n",
    "\n",
    "with open(\"./data/test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)\n",
    "\n",
    "# see the shape\n",
    "all_data = test_data + train_data\n",
    "np.array(all_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:24:00.462430Z",
     "start_time": "2020-08-18T08:24:00.444178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary moved to the bathroom . Sandra journeyed to the bedroom .\n",
      "Is Sandra in the hallway ?\n",
      "n o\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(train_data[0][0]))\n",
    "print(' '.join(train_data[0][1]))\n",
    "print(' '.join(train_data[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:24:00.643229Z",
     "start_time": "2020-08-18T08:24:00.470636Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting up vocabulary\n",
    "vocab = set()\n",
    "for story, question , answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))\n",
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:24:00.668029Z",
     "start_time": "2020-08-18T08:24:00.645984Z"
    }
   },
   "outputs": [],
   "source": [
    "# add an extra space to hold a 0 for Keras's pad_sequences\n",
    "vocab_len = len(vocab) + 1\n",
    "vocab_size = len(vocab) + 1\n",
    "max_story_len = max([len(data[0]) for data in all_data])\n",
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:24:00.689291Z",
     "start_time": "2020-08-18T08:24:00.677302Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'went': 1,\n",
       " 'football': 2,\n",
       " 'journeyed': 3,\n",
       " 'office': 4,\n",
       " '.': 5,\n",
       " 'moved': 6,\n",
       " 'travelled': 7,\n",
       " 'no': 8,\n",
       " 'got': 9,\n",
       " 'is': 10,\n",
       " 'the': 11,\n",
       " 'mary': 12,\n",
       " 'in': 13,\n",
       " 'milk': 14,\n",
       " 'grabbed': 15,\n",
       " 'discarded': 16,\n",
       " 'to': 17,\n",
       " 'there': 18,\n",
       " '?': 19,\n",
       " 'back': 20,\n",
       " 'john': 21,\n",
       " 'sandra': 22,\n",
       " 'dropped': 23,\n",
       " 'down': 24,\n",
       " 'put': 25,\n",
       " 'garden': 26,\n",
       " 'apple': 27,\n",
       " 'hallway': 28,\n",
       " 'picked': 29,\n",
       " 'kitchen': 30,\n",
       " 'took': 31,\n",
       " 'bedroom': 32,\n",
       " 'up': 33,\n",
       " 'bathroom': 34,\n",
       " 'yes': 35,\n",
       " 'left': 36,\n",
       " 'daniel': 37}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:24:00.707962Z",
     "start_time": "2020-08-18T08:24:00.693630Z"
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_stories(data, \n",
    "                      word_index=tokenizer.word_index,\n",
    "                      max_story_len=max_story_len,\n",
    "                      max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    ===================================================================================================\n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "    OUTPUT:\n",
    "    ===================================================================================================\n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    X, Xq, Y = [], [], []\n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "                \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len), pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:24:00.952910Z",
     "start_time": "2020-08-18T08:24:00.711643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story, question, answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "\n",
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)\n",
    "print(len(train_story_text))\n",
    "print(len(train_story_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:24:01.415151Z",
     "start_time": "2020-08-18T08:24:00.960026Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:24:01.960767Z",
     "start_time": "2020-08-18T08:24:01.417980Z"
    }
   },
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))\n",
    "\n",
    "# embed the question into a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)\n",
    "\n",
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)\n",
    "\n",
    "# Reduce with RNN (LSTM)\n",
    "answer = concatenate([response, question_encoded])\n",
    "answer = LSTM(32)(answer)\n",
    "\n",
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:24:02.083444Z",
     "start_time": "2020-08-18T08:24:01.970440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:32:31.792658Z",
     "start_time": "2020-08-18T08:24:02.093704Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 8s 789us/step - loss: 0.9065 - accuracy: 0.4961 - val_loss: 0.6942 - val_accuracy: 0.5030\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.7027 - accuracy: 0.4951 - val_loss: 0.6942 - val_accuracy: 0.4970\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 4s 450us/step - loss: 0.6957 - accuracy: 0.5059 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.6956 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 5s 493us/step - loss: 0.6950 - accuracy: 0.4970 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.6948 - accuracy: 0.4886 - val_loss: 0.6933 - val_accuracy: 0.4910\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 5s 513us/step - loss: 0.6942 - accuracy: 0.5035 - val_loss: 0.6944 - val_accuracy: 0.4970\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 5s 545us/step - loss: 0.6937 - accuracy: 0.5062 - val_loss: 0.6941 - val_accuracy: 0.4970\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 6s 592us/step - loss: 0.6942 - accuracy: 0.5038 - val_loss: 0.6950 - val_accuracy: 0.4970\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 5s 457us/step - loss: 0.6943 - accuracy: 0.5005 - val_loss: 0.6954 - val_accuracy: 0.4980\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.6933 - accuracy: 0.5084 - val_loss: 0.6934 - val_accuracy: 0.5020\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.6835 - accuracy: 0.5446 - val_loss: 0.6663 - val_accuracy: 0.5800\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.6530 - accuracy: 0.6167 - val_loss: 0.6296 - val_accuracy: 0.6540\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.6343 - accuracy: 0.6529 - val_loss: 0.6158 - val_accuracy: 0.6640\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 4s 405us/step - loss: 0.6258 - accuracy: 0.6589 - val_loss: 0.6125 - val_accuracy: 0.6660\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.6144 - accuracy: 0.6706 - val_loss: 0.5985 - val_accuracy: 0.6710\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 4s 399us/step - loss: 0.6041 - accuracy: 0.6756 - val_loss: 0.5928 - val_accuracy: 0.6890\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 4s 351us/step - loss: 0.5896 - accuracy: 0.6967 - val_loss: 0.5713 - val_accuracy: 0.7130\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.5696 - accuracy: 0.7162 - val_loss: 0.5307 - val_accuracy: 0.7390\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.5256 - accuracy: 0.7456 - val_loss: 0.5025 - val_accuracy: 0.7740\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 4s 367us/step - loss: 0.4981 - accuracy: 0.7648 - val_loss: 0.4673 - val_accuracy: 0.7900\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 3s 337us/step - loss: 0.4729 - accuracy: 0.7817 - val_loss: 0.4480 - val_accuracy: 0.8050\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.4545 - accuracy: 0.7957 - val_loss: 0.4745 - val_accuracy: 0.7880\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.4442 - accuracy: 0.7992 - val_loss: 0.4295 - val_accuracy: 0.7950\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.4358 - accuracy: 0.8027 - val_loss: 0.4271 - val_accuracy: 0.8050\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.4222 - accuracy: 0.8105 - val_loss: 0.4211 - val_accuracy: 0.8020\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.4215 - accuracy: 0.8137 - val_loss: 0.4145 - val_accuracy: 0.8080\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 4s 444us/step - loss: 0.4128 - accuracy: 0.8123 - val_loss: 0.4088 - val_accuracy: 0.8130\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.4033 - accuracy: 0.8194 - val_loss: 0.3925 - val_accuracy: 0.8230\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 4s 398us/step - loss: 0.3974 - accuracy: 0.8251 - val_loss: 0.4131 - val_accuracy: 0.8090\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 5s 454us/step - loss: 0.3962 - accuracy: 0.8213 - val_loss: 0.3990 - val_accuracy: 0.8150\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.3889 - accuracy: 0.8308 - val_loss: 0.3878 - val_accuracy: 0.8230\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.3829 - accuracy: 0.8318 - val_loss: 0.3850 - val_accuracy: 0.8250\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.3825 - accuracy: 0.8318 - val_loss: 0.3827 - val_accuracy: 0.8350\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.3742 - accuracy: 0.8329 - val_loss: 0.3916 - val_accuracy: 0.8280\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.3709 - accuracy: 0.8388 - val_loss: 0.3897 - val_accuracy: 0.8210\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 4s 365us/step - loss: 0.3683 - accuracy: 0.8358 - val_loss: 0.3895 - val_accuracy: 0.8210\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 3s 346us/step - loss: 0.3625 - accuracy: 0.8407 - val_loss: 0.3673 - val_accuracy: 0.8340\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 4s 351us/step - loss: 0.3675 - accuracy: 0.8409 - val_loss: 0.4238 - val_accuracy: 0.8100\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 3s 347us/step - loss: 0.3599 - accuracy: 0.8399 - val_loss: 0.3756 - val_accuracy: 0.8270\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.3526 - accuracy: 0.8447 - val_loss: 0.3892 - val_accuracy: 0.8110\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 3s 348us/step - loss: 0.3526 - accuracy: 0.8463 - val_loss: 0.3789 - val_accuracy: 0.8210\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 3s 318us/step - loss: 0.3569 - accuracy: 0.8430 - val_loss: 0.3828 - val_accuracy: 0.8380\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.3558 - accuracy: 0.8462 - val_loss: 0.3713 - val_accuracy: 0.8280\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 4s 411us/step - loss: 0.3445 - accuracy: 0.8498 - val_loss: 0.3848 - val_accuracy: 0.8190\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 4s 400us/step - loss: 0.3449 - accuracy: 0.8505 - val_loss: 0.3836 - val_accuracy: 0.8320\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 4s 438us/step - loss: 0.3476 - accuracy: 0.8472 - val_loss: 0.3736 - val_accuracy: 0.8340\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.3406 - accuracy: 0.8507 - val_loss: 0.3852 - val_accuracy: 0.8240\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.3370 - accuracy: 0.8508 - val_loss: 0.3678 - val_accuracy: 0.8370\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.3370 - accuracy: 0.8548 - val_loss: 0.3885 - val_accuracy: 0.8340\n",
      "Epoch 51/120\n",
      "10000/10000 [==============================] - 3s 330us/step - loss: 0.3362 - accuracy: 0.8509 - val_loss: 0.3637 - val_accuracy: 0.8410\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 5s 451us/step - loss: 0.3319 - accuracy: 0.8523 - val_loss: 0.3949 - val_accuracy: 0.8250\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 4s 440us/step - loss: 0.3301 - accuracy: 0.8559 - val_loss: 0.3825 - val_accuracy: 0.8390\n",
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 3s 329us/step - loss: 0.3300 - accuracy: 0.8552 - val_loss: 0.3993 - val_accuracy: 0.8300\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 3s 296us/step - loss: 0.3252 - accuracy: 0.8564 - val_loss: 0.3936 - val_accuracy: 0.8290\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 3s 319us/step - loss: 0.3278 - accuracy: 0.8555 - val_loss: 0.3701 - val_accuracy: 0.8440\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 4s 364us/step - loss: 0.3209 - accuracy: 0.8586 - val_loss: 0.3838 - val_accuracy: 0.8410\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.3208 - accuracy: 0.8614 - val_loss: 0.3792 - val_accuracy: 0.8310\n",
      "Epoch 59/120\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.3214 - accuracy: 0.8596 - val_loss: 0.3755 - val_accuracy: 0.8400\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 4s 404us/step - loss: 0.3234 - accuracy: 0.8598 - val_loss: 0.3728 - val_accuracy: 0.8380\n",
      "Epoch 61/120\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.3104 - accuracy: 0.8662 - val_loss: 0.4051 - val_accuracy: 0.8320\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.3191 - accuracy: 0.8641 - val_loss: 0.3926 - val_accuracy: 0.8380\n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 4s 436us/step - loss: 0.3152 - accuracy: 0.8638 - val_loss: 0.3820 - val_accuracy: 0.8370\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.3138 - accuracy: 0.8646 - val_loss: 0.4161 - val_accuracy: 0.8290\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.3146 - accuracy: 0.8633 - val_loss: 0.3905 - val_accuracy: 0.8350\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.3047 - accuracy: 0.8692 - val_loss: 0.4205 - val_accuracy: 0.8270\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 4s 399us/step - loss: 0.3055 - accuracy: 0.8702 - val_loss: 0.4108 - val_accuracy: 0.8310\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.3083 - accuracy: 0.8684 - val_loss: 0.4035 - val_accuracy: 0.8360\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 4s 443us/step - loss: 0.3076 - accuracy: 0.8683 - val_loss: 0.3870 - val_accuracy: 0.8350\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 4s 408us/step - loss: 0.3018 - accuracy: 0.8667 - val_loss: 0.3885 - val_accuracy: 0.8350\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.3035 - accuracy: 0.8688 - val_loss: 0.3939 - val_accuracy: 0.8370\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.3006 - accuracy: 0.8690 - val_loss: 0.4061 - val_accuracy: 0.8310\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 6s 609us/step - loss: 0.3035 - accuracy: 0.8708 - val_loss: 0.4079 - val_accuracy: 0.8270\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 5s 518us/step - loss: 0.2985 - accuracy: 0.8712 - val_loss: 0.3921 - val_accuracy: 0.8400\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 5s 478us/step - loss: 0.2934 - accuracy: 0.8738 - val_loss: 0.4041 - val_accuracy: 0.8320\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.2933 - accuracy: 0.8723 - val_loss: 0.4343 - val_accuracy: 0.8300\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 4s 409us/step - loss: 0.2878 - accuracy: 0.8772 - val_loss: 0.4024 - val_accuracy: 0.8350\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 4s 350us/step - loss: 0.2903 - accuracy: 0.8749 - val_loss: 0.4334 - val_accuracy: 0.8230\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.2840 - accuracy: 0.8800 - val_loss: 0.4400 - val_accuracy: 0.8250\n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 3s 311us/step - loss: 0.2887 - accuracy: 0.8751 - val_loss: 0.4195 - val_accuracy: 0.8290\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2822 - accuracy: 0.8809 - val_loss: 0.4395 - val_accuracy: 0.8250\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 3s 326us/step - loss: 0.2797 - accuracy: 0.8795 - val_loss: 0.4449 - val_accuracy: 0.8340\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 4s 411us/step - loss: 0.2824 - accuracy: 0.8776 - val_loss: 0.4170 - val_accuracy: 0.8240\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 3s 332us/step - loss: 0.2750 - accuracy: 0.8835 - val_loss: 0.4341 - val_accuracy: 0.8230\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 3s 289us/step - loss: 0.2813 - accuracy: 0.8815 - val_loss: 0.4354 - val_accuracy: 0.8390\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 3s 315us/step - loss: 0.2775 - accuracy: 0.8799 - val_loss: 0.4377 - val_accuracy: 0.8300\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 3s 289us/step - loss: 0.2734 - accuracy: 0.8830 - val_loss: 0.4609 - val_accuracy: 0.8300\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 3s 288us/step - loss: 0.2725 - accuracy: 0.8842 - val_loss: 0.4619 - val_accuracy: 0.8230\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 3s 291us/step - loss: 0.2698 - accuracy: 0.8841 - val_loss: 0.4448 - val_accuracy: 0.8230\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.2686 - accuracy: 0.8883 - val_loss: 0.4553 - val_accuracy: 0.8340\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 4s 351us/step - loss: 0.2696 - accuracy: 0.8842 - val_loss: 0.4172 - val_accuracy: 0.8270\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.2682 - accuracy: 0.8851 - val_loss: 0.4543 - val_accuracy: 0.8290\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 4s 449us/step - loss: 0.2660 - accuracy: 0.8863 - val_loss: 0.4638 - val_accuracy: 0.8280\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 3s 334us/step - loss: 0.2665 - accuracy: 0.8877 - val_loss: 0.4696 - val_accuracy: 0.8270\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.2686 - accuracy: 0.8861 - val_loss: 0.4906 - val_accuracy: 0.8190\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 5s 453us/step - loss: 0.2680 - accuracy: 0.8877 - val_loss: 0.4633 - val_accuracy: 0.8160\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.2656 - accuracy: 0.8908 - val_loss: 0.4606 - val_accuracy: 0.8240\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 3s 347us/step - loss: 0.2584 - accuracy: 0.8908 - val_loss: 0.4681 - val_accuracy: 0.8260\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 4s 358us/step - loss: 0.2610 - accuracy: 0.8902 - val_loss: 0.4751 - val_accuracy: 0.8240\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 4s 358us/step - loss: 0.2557 - accuracy: 0.8905 - val_loss: 0.5359 - val_accuracy: 0.8240\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.2520 - accuracy: 0.8943 - val_loss: 0.5164 - val_accuracy: 0.8290\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 4s 402us/step - loss: 0.2554 - accuracy: 0.8905 - val_loss: 0.4676 - val_accuracy: 0.8350\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 5s 467us/step - loss: 0.2532 - accuracy: 0.8955 - val_loss: 0.4819 - val_accuracy: 0.8180\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 6s 592us/step - loss: 0.2550 - accuracy: 0.8869 - val_loss: 0.4766 - val_accuracy: 0.8220\n",
      "Epoch 105/120\n",
      "10000/10000 [==============================] - 6s 579us/step - loss: 0.2515 - accuracy: 0.8955 - val_loss: 0.5126 - val_accuracy: 0.8220\n",
      "Epoch 106/120\n",
      "10000/10000 [==============================] - 5s 542us/step - loss: 0.2541 - accuracy: 0.8929 - val_loss: 0.4661 - val_accuracy: 0.8270\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 6s 610us/step - loss: 0.2513 - accuracy: 0.8969 - val_loss: 0.4805 - val_accuracy: 0.8330\n",
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 7s 674us/step - loss: 0.2503 - accuracy: 0.8944 - val_loss: 0.4910 - val_accuracy: 0.8280\n",
      "Epoch 109/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 529us/step - loss: 0.2475 - accuracy: 0.8948 - val_loss: 0.4936 - val_accuracy: 0.8310\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 6s 609us/step - loss: 0.2447 - accuracy: 0.8982 - val_loss: 0.5327 - val_accuracy: 0.8220\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 6s 626us/step - loss: 0.2438 - accuracy: 0.8999 - val_loss: 0.4983 - val_accuracy: 0.8260\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 6s 587us/step - loss: 0.2456 - accuracy: 0.8977 - val_loss: 0.5221 - val_accuracy: 0.8280\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 5s 548us/step - loss: 0.2398 - accuracy: 0.9006 - val_loss: 0.5071 - val_accuracy: 0.8330\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.2411 - accuracy: 0.8984 - val_loss: 0.5098 - val_accuracy: 0.8270\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 3s 333us/step - loss: 0.2364 - accuracy: 0.9001 - val_loss: 0.5002 - val_accuracy: 0.8220\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 5s 498us/step - loss: 0.2435 - accuracy: 0.8996 - val_loss: 0.4748 - val_accuracy: 0.8270\n",
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 6s 553us/step - loss: 0.2434 - accuracy: 0.8997 - val_loss: 0.5409 - val_accuracy: 0.8250\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 6s 600us/step - loss: 0.2403 - accuracy: 0.9022 - val_loss: 0.5382 - val_accuracy: 0.8280\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 5s 526us/step - loss: 0.2344 - accuracy: 0.9027 - val_loss: 0.5587 - val_accuracy: 0.8170\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 6s 590us/step - loss: 0.2300 - accuracy: 0.9061 - val_loss: 0.5515 - val_accuracy: 0.8300\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], \n",
    "                    answers_train,batch_size=32,\n",
    "                    epochs=120,\n",
    "                    validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:32:31.924132Z",
     "start_time": "2020-08-18T08:32:31.799331Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('./model/chatbot_120_epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:42:28.210769Z",
     "start_time": "2020-08-18T08:42:27.970468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:42:29.275580Z",
     "start_time": "2020-08-18T08:42:28.974482Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights('./model/chatbot_120_epochs.h5')\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:42:29.857488Z",
     "start_time": "2020-08-18T08:42:29.846630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n",
      "Is John in the kitchen ?\n",
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)\n",
    "\n",
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)\n",
    "\n",
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:42:31.420687Z",
     "start_time": "2020-08-18T08:42:31.411210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.98681587\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:44:03.147884Z",
     "start_time": "2020-08-18T08:44:03.140253Z"
    }
   },
   "outputs": [],
   "source": [
    "# create own queries\n",
    "# Remember you can only use words from the existing vocab\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_question = \"Is the football in the garden ?\"\n",
    "mydata = [(my_story.split(), my_question.split(), 'yes')]\n",
    "my_story, my_ques,my_ans = vectorize_stories(mydata)\n",
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:44:03.911403Z",
     "start_time": "2020-08-18T08:44:03.904796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.99957865\n"
     ]
    }
   ],
   "source": [
    "# Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
